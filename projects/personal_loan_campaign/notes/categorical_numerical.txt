In decision trees, numerical columns are generally not required to be converted to categorical columns unless the values are very few, which could lead to a very small number of distinct values. In most cases, decision trees can handle numerical features directly and will split them into ranges (e.g., "greater than X" or "less than Y").

However, if the numerical values are sparse or have very few distinct categories, it may be helpful to treat them as categorical, especially if the numeric values do not represent any meaningful order or scale. This can be done by binning or discretizing the numerical values into predefined intervals or categories.

For example, if you have a column like "age" with just a few distinct values, it might make sense to convert it to categorical, where you create categories like "young", "middle-aged", and "old", depending on your context.

Ultimately, the decision depends on the nature of the data and the specific problem you're solving. You might want to try both approaches and evaluate which one works better for your decision tree model's performance.