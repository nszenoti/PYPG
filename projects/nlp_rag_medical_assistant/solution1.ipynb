{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Medical Assistant: Problem Statement (NLP with GenAI)\n",
    "\n",
    "### Business Context\n",
    "\n",
    "The healthcare industry is rapidly evolving, and professionals face increasing challenges in managing vast volumes of medical data while delivering accurate and timely diagnoses. Quick access to comprehensive, reliable, and up-to-date medical knowledge is critical for improving patient outcomes and ensuring informed decision-making in a fast-paced environment.\n",
    "\n",
    "Healthcare professionals often encounter information overload, struggling to sift through extensive research and data to create accurate diagnoses and treatment plans. This challenge is amplified by the need for efficiency, particularly in emergencies, where time-sensitive decisions are vital. Furthermore, access to trusted, current medical information from renowned manuals and research papers is essential for maintaining high standards of care.\n",
    "\n",
    "To address these challenges, healthcare centers can focus on integrating systems that streamline access to medical knowledge, provide tools to support quick decision-making and enhance efficiency. Leveraging centralized knowledge platforms and ensuring healthcare providers have continuous access to reliable resources can significantly improve patient care and operational effectiveness.\n",
    "\n",
    "### Objective\n",
    "\n",
    "As an AI specialist, your task is to develop a RAG-based AI solution using renowned medical manuals to address healthcare challenges. The objective is to understand information overload, apply AI techniques to streamline decision-making, analyze  its impact on diagnostics and patient outcomes, evaluate its potential to standardize care practices, and create a functional prototype demonstrating its feasibility and effectiveness.\n",
    "\n",
    "### Questions to Answer\n",
    "\n",
    "1. What is the protocol for managing sepsis in a critical care unit?\n",
    "2. What are the common symptoms of appendicitis, and can it be cured via medicine? If not, what surgical procedure should be followed to treat it?\n",
    "3. What are the effective treatments or solutions for addressing sudden patchy hair loss, commonly seen as localized bald spots on the scalp, and what could be the possible causes behind it?\n",
    "4. What treatments are recommended for a person who has sustained a physical injury to brain tissue, resulting in temporary or permanent impairment of brain function?\n",
    "5. What are the necessary precautions and treatment steps for a person who has fractured their leg during a hiking trip, and what should be considered for their care and recovery?\n",
    "\n",
    "### Data Dictionary\n",
    "\n",
    "The Merck Manuals are medical references published by the American pharmaceutical company Merck & Co., that cover a wide range of medical topics, including disorders, tests, diagnoses, and drugs. The manuals have been published since 1899 when Merck & Co. was still a subsidiary of the German company Merck.\n",
    "The manual is a PDF with over 4,000 pages divided into 23 sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìÇ **Folder Structure of current task**\n",
    "\n",
    "> **Note:** This folder structure is included just for informational purpose üî≠ \n",
    "> - it outlines how the current task is organized across modules and data files + generated files üßê.\n",
    "\n",
    "```bash\n",
    ".\n",
    "‚îú‚îÄ‚îÄ evaluation_results.json\n",
    "‚îú‚îÄ‚îÄ llm_only_responses.json\n",
    "‚îú‚îÄ‚îÄ prompt_engineering_results.json\n",
    "‚îú‚îÄ‚îÄ rag_optimization_results.json\n",
    "‚îú‚îÄ‚îÄ rag_responses.json\n",
    "‚îú‚îÄ‚îÄ raw_text_backup.pkl\n",
    "‚îú‚îÄ‚îÄ merck_manual_faiss_index\n",
    "‚îÇ¬†¬† ‚îú‚îÄ‚îÄ index.faiss\n",
    "‚îÇ¬†¬† ‚îî‚îÄ‚îÄ index.pkl\n",
    "‚îú‚îÄ‚îÄ merck_manual.pdf\n",
    "‚îú‚îÄ‚îÄ .env\n",
    "‚îú‚îÄ‚îÄ requirements.txt\n",
    "‚îî‚îÄ‚îÄ notebook.ipynb\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìä **LLM + RAG Healthcare Task ‚Äî Flow Diagram (Pseudo Flow)** üìå\n",
    "\n",
    "> **Note:** This document outlines the overall flow of the RAG-based medical assistant solution. It complements the detailed step-by-step implementation plan.\n",
    "\n",
    "##### üîÑ High-Level Task Flow\n",
    "\n",
    "```mermaid\n",
    "journeyFlow\n",
    "\n",
    "    A[Start: Environment Setup] --> B[Data Preparation (Merck Manual)]\n",
    "    B --> C[Text Splitting + Metadata Creation]\n",
    "    C --> D[Generate Embeddings (Titan)]\n",
    "    D --> E[Store in Vector DB (FAISS)]\n",
    "\n",
    "    E --> F[Basic LLM Q&A Setup (Titan Lite)]\n",
    "    F --> G[Prompt Engineering (5+ variations)]\n",
    "\n",
    "    G --> H[RAG Pipeline Setup]\n",
    "    H --> I[Test RAG on Healthcare Questions]\n",
    "\n",
    "    I --> J[Optimize RAG Configs (chunks, k, prompts, etc.)]\n",
    "    J --> K[Evaluation Framework: Groundedness + Relevance]\n",
    "\n",
    "    K --> L[Compare LLM-only vs. RAG]\n",
    "    L --> M[Insights + Recommendations]\n",
    "    M --> N[Documentation + Presentation]\n",
    "    N --> O[End]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Setup\n",
    "\n",
    "- Install necessary libraries\n",
    "\n",
    "- refer requirements.txt (in root folder)\n",
    "  > pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from pypdf import PdfReader\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "# LangChain imports\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_aws import BedrockEmbeddings\n",
    "# ref: issue for langchain_aws: https://github.com/langchain-ai/langchain/issues/2828 so used langchain.llms.Bedrock\n",
    "# prefer using langchain_aws.BedrockLLM instead of langchain.llms.Bedrock\n",
    "from langchain.llms import Bedrock\n",
    "\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import time\n",
    "import datetime\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access environment variables\n",
    "aws_access_key_id = os.getenv('AWS_ACCESS_KEY_ID')\n",
    "aws_secret_access_key = os.getenv('AWS_SECRET_ACCESS_KEY')\n",
    "aws_session_token = os.getenv('AWS_SESSION_TOKEN')\n",
    "aws_region = os.getenv('AWS_REGION')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWS Bedrock setup\n",
    "def get_bedrock_client():\n",
    "    \"\"\"Initialize and return the Bedrock client.\"\"\"\n",
    "    bedrock_client = boto3.client(\n",
    "        service_name=\"bedrock-runtime\",\n",
    "        region_name=aws_region,\n",
    "        aws_access_key_id=aws_access_key_id,\n",
    "        aws_secret_access_key=aws_secret_access_key,\n",
    "        aws_session_token=aws_session_token\n",
    "    )\n",
    "    return bedrock_client\n",
    "\n",
    "bedrock_client = get_bedrock_client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation for RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üîß RAG Data Preparation & Vector Store Creation\n",
    "\n",
    "This section prepares data for the Retrieval-Augmented Generation (RAG) pipeline.  \n",
    "\n",
    "It involves two main steps:\n",
    "\n",
    "1. **Create embeddings** for each text chunk using an embedding model.  \n",
    "2. **Store the embeddings** along with their corresponding text chunks and metadata in a **FAISS vector store** for efficient retrieval.\n",
    "\n",
    "> ‚ö†Ô∏è **Note:** \n",
    ">  \n",
    "> This step is computationally intensive and time-consuming. (so attempted initially)\n",
    ">\n",
    "> \n",
    "> The resulting FAISS index is saved locally to avoid repeating this step in future runs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "\n",
    "def extract_text_from_pdf(pdf_path: str) -> str:\n",
    "    \"\"\"Extract text from a PDF file.\"\"\"\n",
    "    try:\n",
    "        reader = PdfReader(pdf_path)\n",
    "        text = \"\"\n",
    "        for page in tqdm(reader.pages, desc=\"Extracting PDF text\"):\n",
    "            text += page.extract_text() + \"\\n\"\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text from PDF: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def split_text(text: str) -> List[Document]:\n",
    "    \"\"\"Split text into chunks with metadata.\"\"\"\n",
    "    try:\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=1000,\n",
    "            chunk_overlap=200,\n",
    "            separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],\n",
    "            length_function=len\n",
    "        )\n",
    "\n",
    "        chunks = text_splitter.create_documents([text])\n",
    "\n",
    "        # Add metadata to track chunk positions\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            chunk.metadata = {\n",
    "                \"chunk_id\": i,\n",
    "                \"source\": \"Merck Manual\",\n",
    "            }\n",
    "\n",
    "            return chunks\n",
    "    except Exception as e:\n",
    "        print(f\"Error splitting text: {e}\")\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ‚ö†Ô∏è **Warning:**  \n",
    "> The function below extracts text from a PDF file. This is a time-intensive operation.  \n",
    "> To avoid repeated processing, the extracted results are saved in a `.pkl` (pickle) file.  \n",
    "> **Do not run this cell multiple times unnecessarily.** Reuse the saved `.pkl` file instead.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting PDF text: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4114/4114 [03:08<00:00, 21.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 13786695 characters from PDF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: Add a check to see if the file exists, if it does, load it, if it doesn't, run the function and likewise assign the `raw_text` variable\n",
    "\n",
    "# Step 0: Load and process the Merck Manual\n",
    "# NOTE: HEAVY TASK\n",
    "pdf_path = \"merck_manual.pdf\"  # Update with your actual file path\n",
    "raw_text = extract_text_from_pdf(pdf_path)\n",
    "print(f\"Extracted {len(raw_text)} characters from PDF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below are helper functions to save and load the raw text (As Backup)\n",
    "\n",
    "RAW_TEXT_FILE_PATH = \"raw_text_backup.pkl\"\n",
    "def save_raw_text(raw_text, file_path=RAW_TEXT_FILE_PATH):\n",
    "    \"\"\"\n",
    "    Save the extracted raw text to a pickle file.\n",
    "\n",
    "    Args:\n",
    "        raw_text (str): The raw text extracted from the PDF\n",
    "        file_path (str): Path where to save the text\n",
    "    \"\"\"\n",
    "    with open(file_path, 'wb') as f:\n",
    "        pickle.dump(raw_text, f)\n",
    "    print(f\"Raw text saved to {file_path} ({len(raw_text)} characters)\")\n",
    "\n",
    "def load_raw_text(file_path=RAW_TEXT_FILE_PATH):\n",
    "    \"\"\"\n",
    "    Load the raw text from a pickle file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path from where to load the text\n",
    "\n",
    "    Returns:\n",
    "        str: The raw text, or None if file doesn't exist\n",
    "    \"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"Raw text backup not found at {file_path}\")\n",
    "        return None\n",
    "\n",
    "    with open(file_path, 'rb') as f:\n",
    "        raw_text = pickle.load(f)\n",
    "    print(f\"Loaded raw text from {file_path} ({len(raw_text)} characters)\")\n",
    "    return raw_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw text saved to raw_text_backup.pkl (13786695 characters)\n"
     ]
    }
   ],
   "source": [
    "save_raw_text(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded raw text from raw_text_backup.pkl (13786695 characters)\n"
     ]
    }
   ],
   "source": [
    "raw_text = load_raw_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 18212 text chunks\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Split text into chunks\n",
    "chunks = split_text(raw_text)\n",
    "print(f\"Created {len(chunks)} text chunks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embedding Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "BATCH_SIZE = 10\n",
    "CHECKPOINT_FILE = \"embedding_progress.pkl\"\n",
    "STORE_PATH = \"merck_manual_faiss_index\"\n",
    "MODEL_ID = \"amazon.titan-embed-text-v2:0\"\n",
    "EMBEDDING_DIMENSIONS = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings_model():\n",
    "    '''embeddings model that is used to create embeddings'''\n",
    "    return BedrockEmbeddings(\n",
    "        client=bedrock_client,\n",
    "        model_id=MODEL_ID,\n",
    "        model_kwargs={\"dimensions\": EMBEDDING_DIMENSIONS}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create embeddings with checkpointing\n",
    "\n",
    "def create_embeddings_with_checkpoints(chunks, batch_size=BATCH_SIZE, checkpoint_file=CHECKPOINT_FILE):\n",
    "    \"\"\"\n",
    "    Generate embeddings for text chunks with batching and checkpointing support.\n",
    "\n",
    "    This function processes document chunks in batches to generate embeddings efficiently.\n",
    "    It includes checkpoint functionality to save progress and resume from the last successful\n",
    "    batch in case of interruption or failure.\n",
    "\n",
    "    Args:\n",
    "        chunks (List[Document]): List of Document objects containing text to embed\n",
    "        batch_size (int): Number of chunks to process in each batch (default: 20)\n",
    "        checkpoint_file (str): File path to save/load checkpoint data (default: \"embedding_progress.pkl\")\n",
    "\n",
    "    Returns:\n",
    "        tuple: (texts, embeddings, metadatas) where:\n",
    "            - texts (List[str]): List of text content from chunks\n",
    "            - embeddings (List[List[float]]): List of embedding vectors\n",
    "            - metadatas (List[dict]): List of metadata dictionaries\n",
    "\n",
    "    Example:\n",
    "        >>> texts, embeddings, metadatas = create_embeddings_with_checkpoints(chunks)\n",
    "        >>> vector_store = FAISS.from_embeddings(\n",
    "        >>>     text_embeddings=list(zip(texts, embeddings)),\n",
    "        >>>     embedding=embeddings_model,\n",
    "        >>>     metadatas=metadatas\n",
    "        >>> )\n",
    "    \"\"\"\n",
    "\n",
    "    texts = [chunk.page_content for chunk in chunks]\n",
    "    metadatas = [chunk.metadata for chunk in chunks]\n",
    "\n",
    "    # Initialize embedding model\n",
    "    embeddings_model = get_embeddings_model()\n",
    "\n",
    "    # Process embeddings with checkpointing\n",
    "    embeddings = []\n",
    "    start_idx = 0\n",
    "\n",
    "    # Load checkpoint if exists\n",
    "    if os.path.exists(checkpoint_file):\n",
    "        try:\n",
    "            with open(checkpoint_file, 'rb') as f:\n",
    "                checkpoint_data = pickle.load(f)\n",
    "                embeddings = checkpoint_data['embeddings']\n",
    "                start_idx = checkpoint_data['next_idx']\n",
    "                print(f\"Resuming from checkpoint at index {start_idx}/{len(texts)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading checkpoint: {e}. Starting from beginning.\")\n",
    "\n",
    "    try:\n",
    "        # Process in batches with progress bar\n",
    "        for i in tqdm(range(start_idx, len(texts), batch_size),\n",
    "                      desc=\"Generating embeddings\",\n",
    "                      total=(len(texts)-start_idx)//batch_size + 1):\n",
    "            # Get current batch\n",
    "            end_idx = min(i + batch_size, len(texts))\n",
    "            batch = texts[i:end_idx]\n",
    "\n",
    "            # Generate embeddings for batch\n",
    "            batch_embeddings = embeddings_model.embed_documents(batch)\n",
    "            embeddings.extend(batch_embeddings)\n",
    "\n",
    "            # Save checkpoint after each batch\n",
    "            temp_file = checkpoint_file + '.tmp'\n",
    "            with open(temp_file, 'wb') as f:\n",
    "                pickle.dump({\n",
    "                    'embeddings': embeddings,\n",
    "                    'next_idx': end_idx\n",
    "                }, f)\n",
    "\n",
    "            # Atomically replace old checkpoint (ensures  always have a valid checkpoint file)\n",
    "            os.replace(temp_file, checkpoint_file)\n",
    "\n",
    "            # Optional: Add a small delay to avoid rate limiting\n",
    "            time.sleep(0.1)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "        print(f\"Progress saved at index {len(embeddings)}\")\n",
    "        # No need to re-raise, we've saved progress\n",
    "\n",
    "    print(f\"Completed embedding generation: {len(embeddings)}/{len(texts)} chunks\")\n",
    "    return texts, embeddings, metadatas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_store_embeddings(chunks, vector_store_path=STORE_PATH, batch_size=BATCH_SIZE):\n",
    "    \"\"\"\n",
    "    Process document chunks and create a vector store, but only if it doesn't already exist.\n",
    "    Verifies complete embedding generation before creating the vector store.\n",
    "\n",
    "    Args:\n",
    "        chunks (List[Document]): List of Document objects to process\n",
    "        vector_store_path (str): Path where vector store will be saved\n",
    "        batch_size (int): Batch size for embedding generation\n",
    "\n",
    "    Returns:\n",
    "        FAISS or None: The vector store if successful, None if embeddings are incomplete\n",
    "    \"\"\"\n",
    "    # Check if vector store already exists\n",
    "    if os.path.exists(vector_store_path):\n",
    "        print(f\"Vector store already exists at {vector_store_path}. Loading from disk...\")\n",
    "\n",
    "        # Initialize embedding model (needed for loading)\n",
    "        embeddings_model = get_embeddings_model()\n",
    "\n",
    "        # Load existing vector store\n",
    "        vector_store = FAISS.load_local(vector_store_path, embeddings_model)\n",
    "        print(f\"Loaded vector store with {vector_store.index.ntotal} vectors\")\n",
    "        return vector_store\n",
    "\n",
    "    else:\n",
    "        print(\"Vector store not found. Creating new embeddings and vector store...\")\n",
    "\n",
    "        # Generate embeddings with checkpointing\n",
    "        texts, embeddings, metadatas = create_embeddings_with_checkpoints(\n",
    "            chunks,\n",
    "            batch_size=batch_size,\n",
    "            checkpoint_file=CHECKPOINT_FILE\n",
    "        )\n",
    "\n",
    "        # Verify embedding generation is complete\n",
    "        if len(embeddings) < len(chunks):\n",
    "            print(f\"WARNING: Embedding generation is incomplete! Generated {len(embeddings)}/{len(chunks)} embeddings.\")\n",
    "            print(\"Please run the embedding generation process again to complete. (ie process_and_store_embeddings())\")\n",
    "            print(\"The progress has been saved and will resume from where it left off.\")\n",
    "            return None\n",
    "\n",
    "        print(f\"Embedding generation complete: {len(embeddings)}/{len(chunks)} embeddings created.\")\n",
    "\n",
    "        # Initialize embedding model\n",
    "        embeddings_model = get_embeddings_model()\n",
    "\n",
    "        # Create vector store from embeddings\n",
    "        vector_store = FAISS.from_embeddings(\n",
    "            text_embeddings=list(zip(texts, embeddings)),\n",
    "            embedding=embeddings_model,\n",
    "            metadatas=metadatas\n",
    "        )\n",
    "\n",
    "        # Save the vector store\n",
    "        vector_store.save_local(vector_store_path)\n",
    "        print(f\"Created and saved vector store with {len(embeddings)} vectors\")\n",
    "\n",
    "        # Clean up the checkpoint file\n",
    "        if os.path.exists(\"embedding_progress.pkl\"):\n",
    "            os.remove(\"embedding_progress.pkl\")\n",
    "            print(\"Removed checkpoint file\")\n",
    "\n",
    "        return vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store not found. Creating new embeddings and vector store...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1822/1822 [1:48:53<00:00,  3.59s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed embedding generation: 18212/18212 chunks\n",
      "Embedding generation complete: 18212/18212 embeddings created.\n",
      "Created and saved vector store with 18212 vectors\n",
      "Removed checkpoint file\n",
      "Vector store ready for use in RAG pipeline.\n"
     ]
    }
   ],
   "source": [
    "# Step2 :- Create vector store (from Chunks)\n",
    "try:\n",
    "    vector_store = process_and_store_embeddings(chunks)\n",
    "    if vector_store is None:\n",
    "        print(\"Vector store creation failed. Please run the process again to complete embedding generation.\")\n",
    "    else:\n",
    "        print(\"Vector store ready for use in RAG pipeline.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error occurred during vector store creation: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_embeddings_backup(texts, embeddings, metadatas, file_path=\"chunks_embeddings.pkl\"):\n",
    "    \"\"\"\n",
    "    Save the generated embeddings data to a backup file.\n",
    "\n",
    "    Args:\n",
    "        texts (List[str]): List of text chunks\n",
    "        embeddings (List[List[float]]): List of embedding vectors\n",
    "        metadatas (List[dict]): List of metadata dictionaries\n",
    "        file_path (str): Path where to save the backup\n",
    "    \"\"\"\n",
    "    backup_data = {\n",
    "        \"texts\": texts,\n",
    "        \"embeddings\": embeddings,\n",
    "        \"metadatas\": metadatas,\n",
    "        \"count\": len(embeddings),\n",
    "        \"timestamp\": datetime.datetime.now().isoformat()\n",
    "    }\n",
    "\n",
    "    with open(file_path, 'wb') as f:\n",
    "        pickle.dump(backup_data, f)\n",
    "\n",
    "    file_size_mb = os.path.getsize(file_path) / (1024 * 1024)\n",
    "    print(f\"Embeddings backup saved to {file_path}\")\n",
    "    print(f\"Saved {len(embeddings)} embeddings ({file_size_mb:.2f} MB)\")\n",
    "\n",
    "def load_embeddings_backup(file_path=\"chunks_embeddings.pkl\"):\n",
    "    \"\"\"\n",
    "    Load embeddings data from a backup file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path from where to load the backup\n",
    "\n",
    "    Returns:\n",
    "        tuple: (texts, embeddings, metadatas) or (None, None, None) if file doesn't exist\n",
    "    \"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"Embeddings backup not found at {file_path}\")\n",
    "        return None, None, None\n",
    "\n",
    "    with open(file_path, 'rb') as f:\n",
    "        backup_data = pickle.load(f)\n",
    "\n",
    "    texts = backup_data[\"texts\"]\n",
    "    embeddings = backup_data[\"embeddings\"]\n",
    "    metadatas = backup_data[\"metadatas\"]\n",
    "\n",
    "    print(f\"Loaded embeddings backup from {file_path}\")\n",
    "    print(f\"Loaded {len(embeddings)} embeddings (created on {backup_data['timestamp']})\")\n",
    "\n",
    "    return texts, embeddings, metadatas\n",
    "\n",
    "# Usage example - after creating embeddings\n",
    "# save_embeddings_backup(texts, embeddings, metadatas)\n",
    "\n",
    "# Usage example - to load embeddings instead of generating them\n",
    "# texts, embeddings, metadatas = load_embeddings_backup()\n",
    "# if embeddings is not None:\n",
    "#     # Create vector store from loaded embeddings\n",
    "#     vector_store = FAISS.from_embeddings(\n",
    "#         text_embeddings=list(zip(texts, embeddings)),\n",
    "#         embedding=embeddings_model,\n",
    "#         metadatas=metadatas\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_embeddings_from_faiss(vector_store_path=\"merck_manual_faiss_index\"):\n",
    "    \"\"\"\n",
    "    Extract embeddings, texts, and metadata from a saved FAISS vector store.\n",
    "\n",
    "    Args:\n",
    "        vector_store_path (str): Path to the saved FAISS vector store\n",
    "\n",
    "    Returns:\n",
    "        tuple: (texts, embeddings, metadatas) or (None, None, None) if extraction fails\n",
    "    \"\"\"\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "    from langchain_aws import BedrockEmbeddings\n",
    "    from langchain_community.vectorstores import FAISS\n",
    "\n",
    "    try:\n",
    "        # Initialize embedding model (needed for loading)\n",
    "        embeddings_model = BedrockEmbeddings(\n",
    "            client=bedrock_client,\n",
    "            model_id=\"amazon.titan-embed-text-v2:0\",\n",
    "            model_kwargs={\"dimensions\": 516}\n",
    "        )\n",
    "\n",
    "        # Load the vector store\n",
    "        vector_store = FAISS.load_local(vector_store_path, embeddings_model)\n",
    "\n",
    "        # Load the docstore data from the index.pkl file\n",
    "        docstore_path = os.path.join(vector_store_path, \"index.pkl\")\n",
    "        with open(docstore_path, \"rb\") as f:\n",
    "            docstore_data = pickle.load(f)\n",
    "\n",
    "        # Extract texts and metadata\n",
    "        texts = []\n",
    "        metadatas = []\n",
    "\n",
    "        # The docstore contains the mapping between IDs and documents\n",
    "        for doc_id, doc in docstore_data[\"docstore\"]._dict.items():\n",
    "            texts.append(doc.page_content)\n",
    "            metadatas.append(doc.metadata)\n",
    "\n",
    "        # Extract embeddings from the FAISS index\n",
    "        # This gets the raw numpy array of all embeddings\n",
    "        embeddings = vector_store.index.reconstruct_n(0, vector_store.index.ntotal)\n",
    "\n",
    "        print(f\"Extracted {len(texts)} texts, {len(embeddings)} embeddings, and {len(metadatas)} metadata entries\")\n",
    "\n",
    "        # Convert numpy arrays to lists for easier serialization\n",
    "        embeddings_list = [emb.tolist() for emb in embeddings]\n",
    "\n",
    "        return texts, embeddings_list, metadatas\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting data from FAISS index: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "# Usage\n",
    "# texts, embeddings, metadatas = extract_embeddings_from_faiss()\n",
    "# if embeddings is not None:\n",
    "#     # Save as backup\n",
    "#     save_embeddings_backup(texts, embeddings, metadatas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic LLM Implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(llm_response_map):\n",
    "    \"\"\"Print the results of the LLM responses.\"\"\"\n",
    "    for i, (_, data) in enumerate(llm_response_map.items(), start=1):\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"Q{i}: {data['question']}\\n\")\n",
    "        print(f\"A{i}: {data['response']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "MODEL_ID = \"amazon.titan-text-lite-v1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> /var/folders/50/fm7gl9594dsfr5pgv64fl4fh0000gn/T/ipykernel_46379/4153466583.py:20: LangChainDeprecationWarning: The class `Bedrock` was deprecated in LangChain 0.0.34 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-aws package and should be used instead. To use it run `pip install -U :class:`~langchain-aws` and import as `from :class:`~langchain_aws import BedrockLLM``.\n",
    "  self.llm = Bedrock(\n",
    "\n",
    "because of such warning using langchain_aws > BedrockLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_aws import BedrockLLM\n",
    "\n",
    "class LLMHelper:\n",
    "    \"\"\"Helper class to initialize and interact with a Bedrock LLM.\"\"\"\n",
    "\n",
    "    def __init__(self, model_id=MODEL_ID, **model_kwargs):\n",
    "        \"\"\"Initialize the LLM with specified model ID and parameters.\"\"\"\n",
    "        default_params = {\n",
    "            # want factual, stable, and reliable responses.\n",
    "            # ? Low temperature encourages the model to stay deterministic and avoid hallucinations.\n",
    "            # suggested 0.2 !!\n",
    "            \"temperature\": 0.3,\n",
    "            # ! If concerned about response length, you can always instruct the model to be concise in your prompt, but having the 1024 token capacity ensures the model won't be artificially constrained when explaining complex medical concepts.\n",
    "            # ? Medical explanations often require comprehensive context. 1024 tokens (approximately 750-800 words) provides sufficient space to explain medical concepts, protocols, and treatments completely.\n",
    "            \"maxTokenCount\": 1024,\n",
    "            # Allows some diversity in wording, but not too much.\n",
    "            # ? Ensures responses stay on-topic and medically accurate while permitting natural language variations in explanations.\n",
    "            \"topP\": 0.88,\n",
    "        }\n",
    "        params = {**default_params, **model_kwargs}\n",
    "\n",
    "        self.llm = BedrockLLM(\n",
    "            client=bedrock_client,\n",
    "            model_id=model_id,\n",
    "            model_kwargs=params,\n",
    "        )\n",
    "\n",
    "    def generate_response(self, question: str) -> str:\n",
    "        \"\"\"Generate a response using the default prompt.\"\"\"\n",
    "\n",
    "        prompt = f\"\"\"You are a helpful medical assistant with expertise in healthcare.\n",
    "Please answer the following medical question accurately and comprehensively:\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\"\"\"\n",
    "        return self.llm.invoke(prompt)\n",
    "\n",
    "    def generate_response_for_prompt(self, prompt: str) -> str:\n",
    "        \"\"\"Generate a response to a custom prompt.\"\"\"\n",
    "        return self.llm.invoke(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the LLM with default parameters\n",
    "llm_manager = LLMHelper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "‚ö†Ô∏è Bedrock Deprecation Warning in LangChain\n",
    "\n",
    "You may see this warning when using `langchain.llms.Bedrock`:\n",
    "\n",
    "```\n",
    "LangChainDeprecationWarning: The class `Bedrock` was deprecated in LangChain 0.0.34 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-aws package and should be used instead. To use it run `pip install -U :class:`~langchain-aws` and import as `from :class:`~langchain_aws import BedrockLLM``.\n",
    "````\n",
    "\n",
    "üëÄ\n",
    "BedrockLLM is essentially the same as the deprecated Bedrock class, just with a renamed class name in the new package structure. The functionality is identical:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test questions from the problem statement\n",
    "questions = [\n",
    "    \"What is the protocol for managing sepsis in a critical care unit?\",\n",
    "    \"What are the common symptoms of appendicitis, and can it be cured via medicine? If not, what surgical procedure should be followed to treat it?\",\n",
    "    \"What are the effective treatments or solutions for addressing sudden patchy hair loss, commonly seen as localized bald spots on the scalp, and what could be the possible causes behind it?\",\n",
    "    \"What treatments are recommended for a person who has sustained a physical injury to brain tissue, resulting in temporary or permanent impairment of brain function?\",\n",
    "    \"What are the necessary precautions and treatment steps for a person who has fractured their leg during a hiking trip, and what should be considered for their care and recovery?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating response for question 1...\n",
      "Response: \n",
      "Septic shock is a life-threatening medical emergency that requires immediate treatment. The protoco...\n",
      "\n",
      "Generating response for question 2...\n",
      "Response: \n",
      "Appendicitis is a common condition that affects the appendix, a small, tube-like structure at the b...\n",
      "\n",
      "Generating response for question 3...\n",
      "Response: \n",
      "Here are some effective treatments or solutions for addressing sudden patchy hair loss, commonly se...\n",
      "\n",
      "Generating response for question 4...\n",
      "Response: \n",
      "Here are some treatments that may be recommended for a person who has sustained a physical injury t...\n",
      "\n",
      "Generating response for question 5...\n",
      "Response: \n",
      "Here are the necessary precautions and treatment steps for a person who has fractured their leg dur...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate responses for each question\n",
    "llm_only_responses = {}\n",
    "for i, question in enumerate(questions):\n",
    "    print(f\"Generating response for question {i+1}...\")\n",
    "    response = llm_manager.generate_response(question)\n",
    "    llm_only_responses[f\"Question {i+1}\"] = {\n",
    "        \"question\": question,\n",
    "        \"response\": response\n",
    "    }\n",
    "    print(f\"Response: {response[:100]}...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! Run only when you want to generate responses to be saved in a file for future references\n",
    "\n",
    "# Save responses to file\n",
    "with open(\"llm_only_responses.json\", \"w\") as f:\n",
    "    json.dump(llm_only_responses, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëÄ Observations \n",
    "\n",
    "It took aroud 3 mins to generate response to all5 questions !!\n",
    "\n",
    "1. **Sepsis**: A severe infection that can spread throughout the body, requiring immediate medical care. Treatment involves antibiotics, fluids, and possibly surgery or intensive care.\n",
    "\n",
    "2. **Appendicitis**: An inflamed appendix causing severe abdominal pain. The usual treatment is antibiotics and surgery to remove the appendix if necessary.\n",
    "\n",
    "3. **Patchy Hair Loss**: Sudden hair loss might be caused by various factors like genetics or health issues. Treatments can include medication, hair transplants, or lifestyle changes, depending on the cause.\n",
    "\n",
    "4. **Brain Injury**: A physical injury to the brain needs urgent care and may require therapies (physical, speech, etc.) and medications. In severe cases, surgery might be necessary, followed by rehab for recovery.\n",
    "\n",
    "5. **Leg Fracture**: A broken leg requires immediate care like pain management and immobilization, with possible surgery. Rehabilitation and follow-up care are important for recovery.\n",
    "\n",
    "These are all serious health conditions, but with proper treatment and quick medical attention, many can be managed effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Engineering for LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_prompt_variations(question: str):\n",
    "    \"\"\"Test different prompt variations and LLM parameters.\"\"\"\n",
    "    prompt_variations = [\n",
    "        # Variation 1: Basic prompt\n",
    "        {\n",
    "            \"template\": \"Answer the following medical question: {question}\",\n",
    "            \"params\": {\"temperature\": 0.7, \"maxTokenCount\": 1024}\n",
    "        },\n",
    "        # Variation 2: Detailed context\n",
    "        {\n",
    "            \"template\": \"\"\"You are a medical expert with access to the Merck Manual.\n",
    "            Provide a detailed, accurate, and comprehensive answer to the following question.\n",
    "            Include relevant medical terminology and procedures where appropriate.\n",
    "\n",
    "            Question: {question}\n",
    "\n",
    "            Answer:\"\"\",\n",
    "            \"params\": {\"temperature\": 0.5, \"maxTokenCount\": 1500}\n",
    "        },\n",
    "        # Variation 3: Step-by-step reasoning\n",
    "        {\n",
    "            \"template\": \"\"\"As a healthcare professional, answer the following medical question.\n",
    "            First, identify the key medical concepts in the question.\n",
    "            Then, provide a step-by-step explanation with relevant medical information.\n",
    "            Finally, summarize your answer concisely.\n",
    "\n",
    "            Question: {question}\n",
    "\n",
    "            Answer:\"\"\",\n",
    "            \"params\": {\"temperature\": 0.3, \"maxTokenCount\": 1200}\n",
    "        },\n",
    "        # Variation 4: Evidence-based approach\n",
    "        {\n",
    "            \"template\": \"\"\"Based on standard medical guidelines and evidence-based practice:\n",
    "\n",
    "            Question: {question}\n",
    "\n",
    "            Provide a comprehensive answer that includes:\n",
    "            1. Definition and background\n",
    "            2. Key diagnostic criteria or symptoms\n",
    "            3. Standard treatment protocols\n",
    "            4. Important considerations for healthcare providers\n",
    "\n",
    "            Answer:\"\"\",\n",
    "            \"params\": {\"temperature\": 0.4, \"maxTokenCount\": 1300}\n",
    "        },\n",
    "        # Variation 5: Patient-friendly explanation\n",
    "        {\n",
    "            \"template\": \"\"\"Provide a clear, accurate medical answer that would be appropriate for both\n",
    "            healthcare professionals and informed patients. Use plain language where possible\n",
    "            while maintaining medical accuracy.\n",
    "\n",
    "            Question: {question}\n",
    "\n",
    "            Answer:\"\"\",\n",
    "            \"params\": {\"temperature\": 0.6, \"maxTokenCount\": 1100}\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    print(f\"Testing prompt variations for question: {question}\")\n",
    "\n",
    "    results = []\n",
    "    for i, variation in enumerate(prompt_variations):\n",
    "        print(f\"Testing prompt variation {i+1}...\")\n",
    "\n",
    "        # Format the prompt\n",
    "        formatted_prompt = variation[\"template\"].format(question=question)\n",
    "\n",
    "        # Initialize LLM with specific parameters\n",
    "        test_llm = LLMHelper(**variation[\"params\"])\n",
    "\n",
    "        # Generate response (with custom prompt ie not using the default one)\n",
    "        response = test_llm.generate_response_for_prompt(formatted_prompt)\n",
    "\n",
    "        print(f\"Response {i+1}: {response[:125]}...\\n\")\n",
    "\n",
    "        results.append({\n",
    "            \"variation\": i+1,\n",
    "            \"prompt\": variation[\"template\"],\n",
    "            \"parameters\": variation[\"params\"],\n",
    "            \"response\": response\n",
    "        })\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing prompt variations for question 1...\n",
      "Testing prompt variations for question: What is the protocol for managing sepsis in a critical care unit?\n",
      "Testing prompt variation 1...\n",
      "Response 1: \n",
      "Sepsis is a serious medical condition that occurs when the body's response to an infection injures its own tissues and organ...\n",
      "\n",
      "Testing prompt variation 2...\n",
      "Response 2:  The protocol for managing sepsis in a critical care unit involves a combination of early detection, rapid diagnosis, and agg...\n",
      "\n",
      "Testing prompt variation 3...\n",
      "Response 3: \n",
      "            The protocol for managing sepsis in a critical care unit involves early identification, rapid assessment, and pr...\n",
      "\n",
      "Testing prompt variation 4...\n",
      "Response 4: \n",
      "Sepsis is a serious medical condition that requires immediate medical attention. It is a life-threatening condition that occ...\n",
      "\n",
      "Testing prompt variation 5...\n",
      "Response 5:  Sepsis is a life-threatening condition that requires immediate medical attention. In a critical care unit, sepsis management...\n",
      "\n",
      "\n",
      "Testing prompt variations for question 2...\n",
      "Testing prompt variations for question: What are the common symptoms of appendicitis, and can it be cured via medicine? If not, what surgical procedure should be followed to treat it?\n",
      "Testing prompt variation 1...\n",
      "Response 1: \n",
      "The most common symptoms of appendicitis include abdominal pain in the lower right side, nausea, vomiting, fever, and loss o...\n",
      "\n",
      "Testing prompt variation 2...\n",
      "Response 2:  The most common symptoms of appendicitis include abdominal pain in the lower right side, nausea, vomiting, fever, and loss o...\n",
      "\n",
      "Testing prompt variation 3...\n",
      "Response 3: \n",
      "            Common symptoms of appendicitis include abdominal pain, nausea, vomiting, fever, and loss of appetite. While app...\n",
      "\n",
      "Testing prompt variation 4...\n",
      "Response 4: \n",
      "            Appendicitis is a common condition characterized by abdominal pain, nausea, vomiting, fever, and loss of appetit...\n",
      "\n",
      "Testing prompt variation 5...\n",
      "Response 5:  The common symptoms of appendicitis include abdominal pain, nausea, vomiting, fever, and loss of appetite. While some cases ...\n",
      "\n",
      "\n",
      "Testing prompt variations for question 3...\n",
      "Testing prompt variations for question: What are the effective treatments or solutions for addressing sudden patchy hair loss, commonly seen as localized bald spots on the scalp, and what could be the possible causes behind it?\n",
      "Testing prompt variation 1...\n",
      "Response 1: \n",
      "Here are some effective treatments or solutions for addressing sudden patchy hair loss, commonly seen as localized bald spot...\n",
      "\n",
      "Testing prompt variation 2...\n",
      "Response 2:  Sudden patchy hair loss, commonly known as localized bald spots on the scalp, can be caused by various factors, including ho...\n",
      "\n",
      "Testing prompt variation 3...\n",
      "Response 3: \n",
      "            1. Effective Treatments:\n",
      "            1. Minoxidil (Rogaine): Minoxidil is a topical medication that is applied d...\n",
      "\n",
      "Testing prompt variation 4...\n",
      "Response 4: \n",
      "\n",
      "            Sudden patchy hair loss, commonly known as localized bald spots on the scalp, can be caused by a variety of fac...\n",
      "\n",
      "Testing prompt variation 5...\n",
      "Response 5:  Effective treatments for sudden patchy hair loss include medications such as minoxidil (Rogaine) and finasteride (Propecia)....\n",
      "\n",
      "\n",
      "Testing prompt variations for question 4...\n",
      "Testing prompt variations for question: What treatments are recommended for a person who has sustained a physical injury to brain tissue, resulting in temporary or permanent impairment of brain function?\n",
      "Testing prompt variation 1...\n",
      "Response 1: \n",
      "There are several treatments recommended for a person who has sustained a physical injury to brain tissue, resulting in temp...\n",
      "\n",
      "Testing prompt variation 2...\n",
      "Response 2:  The treatments for a person who has sustained a physical injury to brain tissue, resulting in temporary or permanent impairm...\n",
      "\n",
      "Testing prompt variation 3...\n",
      "Response 3: \n",
      "            Treatments for brain injury include medication, physical therapy, occupational therapy, speech therapy, and reha...\n",
      "\n",
      "Testing prompt variation 4...\n",
      "Response 4: \n",
      "\n",
      "            Definition and background:\n",
      "            A physical injury to brain tissue, whether temporary or permanent, can h...\n",
      "\n",
      "Testing prompt variation 5...\n",
      "Response 5:  The treatment for a person with brain injury depends on the type and severity of the injury. In some cases, treatment may in...\n",
      "\n",
      "\n",
      "Testing prompt variations for question 5...\n",
      "Testing prompt variations for question: What are the necessary precautions and treatment steps for a person who has fractured their leg during a hiking trip, and what should be considered for their care and recovery?\n",
      "Testing prompt variation 1...\n",
      "Response 1: \n",
      "Here are the necessary precautions and treatment steps for a person who has fractured their leg during a hiking trip:\n",
      "\n",
      "1. Tr...\n",
      "\n",
      "Testing prompt variation 2...\n",
      "Response 2: \n",
      "Here are the necessary precautions and treatment steps for a person who has fractured their leg during a hiking trip:\n",
      "\n",
      "Preca...\n",
      "\n",
      "Testing prompt variation 3...\n",
      "Response 3: \n",
      "            Necessary precautions and treatment steps for a person who has fractured their leg during a hiking trip include:...\n",
      "\n",
      "Testing prompt variation 4...\n",
      "Response 4: \n",
      "            A person who has fractured their leg during a hiking trip should receive immediate medical attention. The necess...\n",
      "\n",
      "Testing prompt variation 5...\n",
      "Response 5:  If a person fractures their leg during a hiking trip, immediate medical attention is crucial. The first step is to assess th...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test prompt variations for each question\n",
    "prompt_engineering_results = {}\n",
    "\n",
    "for i, question in enumerate(questions):\n",
    "    print(f\"\\nTesting prompt variations for question {i+1}...\")\n",
    "\n",
    "    results = test_prompt_variations(question)\n",
    "    prompt_engineering_results[f\"Question {i+1}\"] = {\n",
    "        \"question\": question,\n",
    "        \"variations\": results\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to file\n",
    "with open(\"prompt_engineering_results.json\", \"w\") as f:\n",
    "    json.dump(prompt_engineering_results, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëÄ **Observations**\n",
    "\n",
    "It took around 5 minutes to address all questions with different variations in prompt \n",
    "\n",
    "**Prompt Engineering Results - Quick Observations**\n",
    "\n",
    "1. **Response Length**: Higher temperature settings (0.6-0.7) created longer answers; lower temperatures (0.3-0.4) gave more concise responses.\n",
    "\n",
    "2. **Structure Matters**: Prompts that asked for step-by-step explanations produced more organized answers.\n",
    "\n",
    "3. **Role-Playing Works**: When the AI was told to be a \"medical expert,\" it used more technical language.\n",
    "\n",
    "4. **Best Performers**:\n",
    "   - For clear structure: Variation 3 (temp 0.3)\n",
    "   - For technical detail: Variation 2 (temp 0.5)\n",
    "   - For easy-to-understand language: Variation 5 (temp 0.6)\n",
    "\n",
    "5. **Content Quality**: The core medical information stayed consistent across all variations, just presented differently.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rag Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_aws import BedrockLLM\n",
    "\n",
    "# TODO: create a custom helper method to get llm instance (maybe via langchain_aws or langchain.llms.Bedrock)\n",
    "\n",
    "def initialize_llm_for_rag(model_id=MODEL_ID, **model_kwargs):\n",
    "    \"\"\"Initialize the Bedrock LLM with specified parameters.\"\"\"\n",
    "    default_params = {\n",
    "        # ! even lower temperature because the model is now grounding its responses in retrieved text rather than generating from its parameters\n",
    "        \"temperature\": 0.25,\n",
    "        # *increase max tokens slightly because RAG responses often need to synthesize information from multiple retrieved chunks. The additional tokens allow for more comprehensive integration of the retrieved medical information.\n",
    "        \"maxTokenCount\": 1500,\n",
    "        # ? a slightly lower top_p with RAG because the retrieved context already provides the necessary information. A lower top_p helps the model stay more focused on the most probable tokens derived from the retrieved medical text.\n",
    "        \"topP\": 0.8,\n",
    "    }\n",
    "\n",
    "    # Update default parameters with any provided ones\n",
    "    params = {**default_params, **model_kwargs}\n",
    "\n",
    "    #llm = Bedrock(\n",
    "    llm = BedrockLLM(\n",
    "        client=bedrock_client,\n",
    "        model_id=model_id,\n",
    "        model_kwargs=params\n",
    "    )\n",
    "\n",
    "    return llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_rag_pipeline(vector_store, llm):\n",
    "    \"\"\"Set up a RAG pipeline with the vector store and LLM.\"\"\"\n",
    "\n",
    "    # Create retriever\n",
    "    retriever = vector_store.as_retriever(\n",
    "        search_type=\"similarity\",\n",
    "        search_kwargs={\"k\": 5}\n",
    "    )\n",
    "\n",
    "    # Create RAG prompt template\n",
    "    rag_prompt_template = \"\"\"You are a medical assistant with expertise in healthcare.\n",
    "    Use the following context from the Merck Manual to answer the question accurately.\n",
    "    If the context doesn't contain the answer, say so and provide general medical knowledge.\n",
    "\n",
    "    Context:\n",
    "    {context}\n",
    "\n",
    "    Question: {question}\n",
    "\n",
    "    Answer:\"\"\"\n",
    "\n",
    "    rag_prompt = PromptTemplate.from_template(rag_prompt_template)\n",
    "\n",
    "    # Create RAG chain\n",
    "    rag_chain = (\n",
    "        {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "        | rag_prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    return rag_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up RAG pipeline\n",
    "llm = initialize_llm_for_rag()\n",
    "rag_chain = setup_rag_pipeline(vector_store, llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating RAG response for question 1...\n",
      "Response:  Fluid resuscitation with 0.9% saline should be given until CVP reaches 8 mm Hg (10 cm H2O) or PAOP reaches 12 to 15 mm ...\n",
      "\n",
      "Generating RAG response for question 2...\n",
      "Response:  Common symptoms of appendicitis include abdominal pain, nausea, vomiting, anorexia, and low-grade fever. While appendic...\n",
      "\n",
      "Generating RAG response for question 3...\n",
      "Response:  The effective treatments or solutions for addressing sudden patchy hair loss, commonly seen as localized bald spots on ...\n",
      "\n",
      "Generating RAG response for question 4...\n",
      "Response:  The cornerstone of management for all patients is maintenance of adequate ventilation, oxygenation, and brain perfusion...\n",
      "\n",
      "Generating RAG response for question 5...\n",
      "Response:  The necessary precautions and treatment steps for a person who has fractured their leg during a hiking trip, and what s...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate RAG responses for each question\n",
    "rag_responses = {}\n",
    "for i, question in enumerate(questions):\n",
    "    print(f\"Generating RAG response for question {i+1}...\")\n",
    "    response = rag_chain.invoke(question)\n",
    "    rag_responses[f\"Question {i+1}\"] = {\n",
    "        \"question\": question,\n",
    "        \"response\": response\n",
    "    }\n",
    "    print(f\"Response: {response[:120]}...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save responses to file\n",
    "with open(\"rag_responses.json\", \"w\") as f:\n",
    "    json.dump(rag_responses, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëÄ **TakeAways**\n",
    "\n",
    "This RAG setup combines deep medical knowledge with AI's language ability to generate helpful, factual, and structured answers. It mirrors how a trained doctor might respond‚Äîoften detailed and cautious, but sometimes abrupt or overly technical.\n",
    "\n",
    "> **It took only 35 seconds to generate the answers for all 5 questions** (ie pretty fast ü§î)\n",
    "\n",
    "**Summary of RAG Responses**\n",
    "\n",
    "This file contains 5 medical questions with their corresponding AI-generated answers. The quality and completeness of these responses vary significantly:\n",
    "\n",
    "1. **Sepsis management**: Very detailed response with specific treatments, medications, and dosages.\n",
    "\n",
    "2. **Appendicitis**: Extremely brief response that contradicts itself (says it \"can be cured via medicine\" but then immediately states it \"is a surgical condition\").\n",
    "\n",
    "3. **Hair loss**: Lists many possible causes but doesn't clearly explain treatments despite the question asking for both.\n",
    "\n",
    "4. **Brain injury**: Very brief response focusing only on basic management principles.\n",
    "\n",
    "5. **Leg fracture**: Brief response with basic care instructions but missing important emergency first aid information relevant to a hiking scenario.\n",
    "\n",
    "**Observations**\n",
    "\n",
    "- **Inconsistent detail level**: Some answers are comprehensive while others are minimal.\n",
    "- **Accuracy issues**: The appendicitis answer contains contradictory information.\n",
    "- **Missing information**: Several responses don't fully address the questions asked.\n",
    "- **Format inconsistency**: Some responses use bullet points while others are paragraphs.\n",
    "- **Context awareness**: The leg fracture response doesn't address the hiking emergency context.\n",
    "\n",
    "These inconsistencies suggest the RAG system might need improvement in how it retrieves and synthesizes medical information to provide more consistent, accurate, and complete responses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RAG Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vector_store(chunks: List[Document]):\n",
    "    \"\"\"Create a vector store from document chunks.\"\"\"\n",
    "    # Initialize the Titan Embeddings model\n",
    "    embeddings = BedrockEmbeddings(\n",
    "        client=bedrock_client,\n",
    "        model_id=MODEL_ID\n",
    "    )\n",
    "\n",
    "    # Create vector store\n",
    "    vector_store = FAISS.from_documents(\n",
    "        documents=chunks,\n",
    "        embedding=embeddings\n",
    "    )\n",
    "\n",
    "    return vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_rag_pipeline(vector_store, question):\n",
    "    \"\"\"Test different RAG configurations for a question without re-chunking.\n",
    "\n",
    "    Why ? Re-chunking (ie altering chunk size and overlap values) is a costly operation and should be avoided if possible as it consumes a lot of time, whilst creating embeddings.\n",
    "    \"\"\"\n",
    "\n",
    "    # Configuration variations to test (only retriever_k and llm_params)\n",
    "    configurations = [\n",
    "        # Variation 1: Default configuration\n",
    "        {\n",
    "            \"retriever_k\": 5,\n",
    "            \"llm_params\": {\"temperature\": 0.5, \"maxTokenCount\": 1500}\n",
    "        },\n",
    "        # Variation 2: More retrieval context\n",
    "        {\n",
    "            \"retriever_k\": 8,\n",
    "            \"llm_params\": {\"temperature\": 0.4, \"maxTokenCount\": 1500}\n",
    "        },\n",
    "        # Variation 3: Less retrieval context\n",
    "        {\n",
    "            \"retriever_k\": 3,\n",
    "            \"llm_params\": {\"temperature\": 0.5, \"maxTokenCount\": 1800}\n",
    "        },\n",
    "        # Variation 4: More creative generation\n",
    "        {\n",
    "            \"retriever_k\": 5,\n",
    "            \"llm_params\": {\"temperature\": 0.7, \"maxTokenCount\": 1500}\n",
    "        },\n",
    "        # Variation 5: More precise generation\n",
    "        {\n",
    "            \"retriever_k\": 5,\n",
    "            \"llm_params\": {\"temperature\": 0.2, \"maxTokenCount\": 1500}\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    print(f\"Testing RAG configurations for question: {question} --->\")\n",
    "\n",
    "    results = []\n",
    "    for i, config in enumerate(configurations):\n",
    "        print(f\"Testing RAG configuration {i+1}...\")\n",
    "\n",
    "        # Create retriever with specific k value\n",
    "        test_retriever = vector_store.as_retriever(\n",
    "            search_type=\"similarity\",\n",
    "            search_kwargs={\"k\": config[\"retriever_k\"]}\n",
    "        )\n",
    "\n",
    "        # Initialize LLM with specific parameters\n",
    "        test_llm = initialize_llm_for_rag(**config[\"llm_params\"])\n",
    "\n",
    "        # Create RAG prompt\n",
    "        rag_prompt_template = \"\"\"You are a medical assistant with expertise in healthcare.\n",
    "        Use the following context from the Merck Manual to answer the question accurately.\n",
    "        If the context doesn't contain the answer, say so and provide general medical knowledge.\n",
    "\n",
    "        Context:\n",
    "        {context}\n",
    "\n",
    "        Question: {question}\n",
    "\n",
    "        Answer:\"\"\"\n",
    "\n",
    "        rag_prompt = PromptTemplate.from_template(rag_prompt_template)\n",
    "\n",
    "        # Create RAG chain\n",
    "        test_rag_chain = (\n",
    "            {\"context\": test_retriever, \"question\": RunnablePassthrough()}\n",
    "            | rag_prompt\n",
    "            | test_llm\n",
    "            | StrOutputParser()\n",
    "        )\n",
    "\n",
    "        # Generate response\n",
    "        response = test_rag_chain.invoke(question)\n",
    "\n",
    "        print(f\"Response {i+1}: {response[:120]}...\\n\")\n",
    "\n",
    "        results.append({\n",
    "            \"configuration\": i+1,\n",
    "            \"settings\": config,\n",
    "            \"response\": response\n",
    "        })\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimizing RAG for question 1...\n",
      "Testing RAG configurations for question: What is the protocol for managing sepsis in a critical care unit? --->\n",
      "Testing RAG configuration 1...\n",
      "Response 1:  The first step is to keep the patient warm. Then, hemorrhage is controlled, airway and ventilation are checked, and res...\n",
      "\n",
      "Testing RAG configuration 2...\n",
      "Response 2:  Fluid resuscitation with 0.9% saline should be given until CVP reaches 8 mm Hg (10 cm H2O) or PAOP reaches 12 to 15 mm ...\n",
      "\n",
      "Testing RAG configuration 3...\n",
      "Response 3:  Fluid resuscitation, broad-spectrum antibiotics, drainage of abscesses, and normalization of blood glucose levels....\n",
      "\n",
      "Testing RAG configuration 4...\n",
      "Response 4:  Fluid resuscitation with 0.9% saline should be given until CVP reaches 8 mm Hg (10 cm H2O) or PAOP reaches 12 to 15 mm ...\n",
      "\n",
      "Testing RAG configuration 5...\n",
      "Response 5:  Fluid resuscitation with 0.9% saline should be given until CVP reaches 8 mm Hg (10 cm H2O) or PAOP reaches 12 to 15 mm ...\n",
      "\n",
      "\n",
      "Optimizing RAG for question 2...\n",
      "Testing RAG configurations for question: What are the common symptoms of appendicitis, and can it be cured via medicine? If not, what surgical procedure should be followed to treat it? --->\n",
      "Testing RAG configuration 1...\n",
      "Response 1:  Appendicitis is characterized by abdominal pain, anorexia, and abdominal tenderness. It is a common cause of acute abdo...\n",
      "\n",
      "Testing RAG configuration 2...\n",
      "Response 2: Sorry - this model is unable to respond to this request....\n",
      "\n",
      "Testing RAG configuration 3...\n",
      "Response 3: Sorry - this model is unable to respond to this request....\n",
      "\n",
      "Testing RAG configuration 4...\n",
      "Response 4: Sorry - this model is unable to respond to this request....\n",
      "\n",
      "Testing RAG configuration 5...\n",
      "Response 5: Sorry - this model is unable to respond to this request....\n",
      "\n",
      "\n",
      "Optimizing RAG for question 3...\n",
      "Testing RAG configurations for question: What are the effective treatments or solutions for addressing sudden patchy hair loss, commonly seen as localized bald spots on the scalp, and what could be the possible causes behind it? --->\n",
      "Testing RAG configuration 1...\n",
      "Response 1:  The most common type of hair loss is androgenetic alopecia, which is the most common type of hair loss. Other than hair...\n",
      "\n",
      "Testing RAG configuration 2...\n",
      "Response 2:  Androgenetic alopecia (male-pattern and female-pattern hair loss) is the most common type of hair loss. Concomitant vir...\n",
      "\n",
      "Testing RAG configuration 3...\n",
      "Response 3:  The most effective treatment for sudden patchy hair loss is minoxidil, which is an over-the-counter topical solution. I...\n",
      "\n",
      "Testing RAG configuration 4...\n",
      "Response 4:  Androgenetic Alopecia, which is a hereditary condition that affects both men and women, is the most common cause of sud...\n",
      "\n",
      "Testing RAG configuration 5...\n",
      "Response 5:  Androgenetic alopecia (male-pattern or female-pattern hair loss) is the most common type of hair loss. Concomitant viri...\n",
      "\n",
      "\n",
      "Optimizing RAG for question 4...\n",
      "Testing RAG configurations for question: What treatments are recommended for a person who has sustained a physical injury to brain tissue, resulting in temporary or permanent impairment of brain function? --->\n",
      "Testing RAG configuration 1...\n",
      "Response 1:  The cornerstone of management for all patients is maintenance of adequate ventilation, oxygenation, and brain perfusion...\n",
      "\n",
      "Testing RAG configuration 2...\n",
      "Response 2:  The cornerstone of management for all patients is maintenance of adequate ventilation, oxygenation, and brain perfusion...\n",
      "\n",
      "Testing RAG configuration 3...\n",
      "Response 3:  Surgery may be necessary in patients with more severe injuries to place monitors to track and treat intracranial pressu...\n",
      "\n",
      "Testing RAG configuration 4...\n",
      "Response 4:  Surgery is often needed in patients with more severe injury to place monitors to track and treat intracranial pressure,...\n",
      "\n",
      "Testing RAG configuration 5...\n",
      "Response 5:  The cornerstone of management for all patients is maintenance of adequate ventilation, oxygenation, and brain perfusion...\n",
      "\n",
      "\n",
      "Optimizing RAG for question 5...\n",
      "Testing RAG configurations for question: What are the necessary precautions and treatment steps for a person who has fractured their leg during a hiking trip, and what should be considered for their care and recovery? --->\n",
      "Testing RAG configuration 1...\n",
      "Response 1:  The necessary precautions and treatment steps for a person who has fractured their leg during a hiking trip, and what s...\n",
      "\n",
      "Testing RAG configuration 2...\n",
      "Response 2:  The Merck Manual of Diagnosis & Therapy, 19th Edition Chapter 338. Exercise & Sports Injury 3489 nipunshah6776@gmail.co...\n",
      "\n",
      "Testing RAG configuration 3...\n",
      "Response 3:  The Merck Manual of Diagnosis & Therapy, 19th Edition Chapter 350. Rehabilitation 3634 nipunshah6776@gmail.com 0W3XG8QC...\n",
      "\n",
      "Testing RAG configuration 4...\n",
      "Response 4:  The necessary precautions and treatment steps for a person who has fractured their leg during a hiking trip include:\n",
      "  ...\n",
      "\n",
      "Testing RAG configuration 5...\n",
      "Response 5:  The necessary precautions and treatment steps for a person who has fractured their leg during a hiking trip, and what s...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test RAG optimization for each question\n",
    "rag_optimization_results = {}\n",
    "for i, question in enumerate(questions):\n",
    "    print(f\"\\nOptimizing RAG for question {i+1}...\")\n",
    "    results = optimize_rag_pipeline(vector_store, question)\n",
    "    rag_optimization_results[f\"Question {i+1}\"] = {\n",
    "        \"question\": question,\n",
    "        \"configurations\": results\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to file\n",
    "with open(\"rag_optimization_results.json\", \"w\") as f:\n",
    "    json.dump(rag_optimization_results, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üßê **Summary** \n",
    "\n",
    "This experiment tested different configurations for a medical question-answering system, varying two key parameters:\n",
    "\n",
    "- **Retriever_k**: The number of documents retrieved (3-8)\n",
    "- **Temperature**: Controls randomness in responses (0.2-0.7)\n",
    "\n",
    "**NOTE**:\n",
    "- It was conducted in an around **3 mins**\n",
    "- Task completed in lesser time than llms standalone responses (ie without tuned)\n",
    "- This suggest providing context, somehow helps llm to deduce the responses faster !! \n",
    "\n",
    "**Key Findings**:\n",
    "\n",
    "1. **More retrieval isn't always better**: Configuration 5 (k=5, temp=0.2) consistently produced the most detailed and accurate responses.\n",
    "\n",
    "2. **Lower temperature (0.2-0.4)** generally produced more comprehensive and factual answers compared to higher temperatures.\n",
    "\n",
    "3. **Response quality varied dramatically** across questions - some received detailed answers while others got minimal or incorrect information.\n",
    "\n",
    "4. **System limitations**: For some medical questions (particularly appendicitis), most configurations failed completely.\n",
    "\n",
    "5. **Best balance**: The optimal configuration appears to be moderate retrieval (k=5) with low temperature (0.2) for medical information retrieval.\n",
    "\n",
    "This suggests that fine-tuning these parameters is crucial for reliable medical information retrieval, with quality being more important than quantity of retrieved documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_evaluation_results(result_map):\n",
    "    pprint(result_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_aws import BedrockLLM\n",
    "\n",
    "# TODO: create a custom helper method to get llm instance (maybe via langchain_aws or langchain.llms.Bedrock)\n",
    "\n",
    "def initialize_llm_for_eval(model_id=MODEL_ID, **model_kwargs):\n",
    "    \"\"\"Initialize the Bedrock LLM with specified parameters.\"\"\"\n",
    "    default_params = {\n",
    "        # ! even lower temperature because the model is now grounding its responses in retrieved text rather than generating from its parameters\n",
    "        \"temperature\": 0.2,\n",
    "        # *increase max tokens slightly because RAG responses often need to synthesize information from multiple retrieved chunks. The additional tokens allow for more comprehensive integration of the retrieved medical information.\n",
    "        \"maxTokenCount\": 1000,\n",
    "    }\n",
    "\n",
    "    # Update default parameters with any provided ones\n",
    "    params = {**default_params, **model_kwargs}\n",
    "\n",
    "    #llm = Bedrock(\n",
    "    llm = BedrockLLM(\n",
    "        client=bedrock_client,\n",
    "        model_id=model_id,\n",
    "        model_kwargs=params\n",
    "    )\n",
    "\n",
    "    return llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_groundedness(question, response, context=None):\n",
    "    \"\"\"Evaluate the groundedness of a response.\"\"\"\n",
    "\n",
    "    if context:\n",
    "        evaluation_prompt = f\"\"\"You are an objective evaluator assessing the groundedness of a medical response.\n",
    "\n",
    "        Question: {question}\n",
    "\n",
    "        Response to evaluate: {response}\n",
    "\n",
    "        Context from source material: {context}\n",
    "\n",
    "        Evaluate the groundedness of the response on a scale of 1-10, where:\n",
    "        1 = Not grounded at all, contains information contradicting the source material\n",
    "        5 = Partially grounded, some information is accurate but contains unsupported claims\n",
    "        10 = Completely grounded, all information is supported by the source material\n",
    "\n",
    "        Provide your rating and a brief explanation of your assessment.\n",
    "        \"\"\"\n",
    "    else:\n",
    "        evaluation_prompt = f\"\"\"You are an objective evaluator assessing the groundedness of a medical response.\n",
    "\n",
    "        Question: {question}\n",
    "\n",
    "        Response to evaluate: {response}\n",
    "\n",
    "        Evaluate the groundedness of the response on a scale of 1-10, where:\n",
    "        1 = Not grounded at all, contains information that contradicts medical knowledge\n",
    "        5 = Partially grounded, some information is accurate but contains questionable claims\n",
    "        10 = Completely grounded, all information aligns with established medical knowledge\n",
    "\n",
    "        Provide your rating and a brief explanation of your assessment.\n",
    "        \"\"\"\n",
    "\n",
    "    # Use a lower temperature for evaluation to get more consistent results\n",
    "    eval_llm = initialize_llm_for_eval()\n",
    "    evaluation = eval_llm.invoke(evaluation_prompt)\n",
    "\n",
    "    return evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_relevance(question, response):\n",
    "    \"\"\"Evaluate the relevance of a response to the question.\"\"\"\n",
    "\n",
    "    evaluation_prompt = f\"\"\"You are an objective evaluator assessing the relevance of a medical response.\n",
    "\n",
    "    Question: {question}\n",
    "\n",
    "    Response to evaluate: {response}\n",
    "\n",
    "    Evaluate the relevance of the response on a scale of 1-10, where:\n",
    "    1 = Not relevant at all, does not address the question\n",
    "    5 = Partially relevant, addresses some aspects of the question but misses key points\n",
    "    10 = Completely relevant, directly and comprehensively addresses all aspects of the question\n",
    "\n",
    "    Provide your rating and a brief explanation of your assessment.\n",
    "    \"\"\"\n",
    "\n",
    "    # Use a lower temperature for evaluation to get more consistent results\n",
    "    eval_llm = initialize_llm_for_eval()\n",
    "    evaluation = eval_llm.invoke(evaluation_prompt)\n",
    "\n",
    "    return evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate all responses\n",
    "evaluation_results = {\n",
    "    \"llm_only\": {},\n",
    "    \"rag\": {}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate LLM-only responses\n",
    "for question_key, data in llm_only_responses.items():\n",
    "    question = data[\"question\"]\n",
    "    response = data[\"response\"]\n",
    "\n",
    "    groundedness = evaluate_groundedness(question, response)\n",
    "    relevance = evaluate_relevance(question, response)\n",
    "\n",
    "    evaluation_results[\"llm_only\"][question_key] = {\n",
    "        \"groundedness\": groundedness,\n",
    "        \"relevance\": relevance\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM-only Evaluation Results: \n",
      "\n",
      "{'Question 1': {'groundedness': '10 - Completely grounded, all information '\n",
      "                                'aligns with established medical knowledge. '\n",
      "                                'Sepsis is a life-threatening medical '\n",
      "                                'emergency that requires immediate treatment. '\n",
      "                                'The protocol for managing sepsis in a '\n",
      "                                'critical care unit involves a combination of '\n",
      "                                'interventions, including rapid assessment and '\n",
      "                                'diagnosis, fluid resuscitation, antibiotics, '\n",
      "                                'vasopressors, inotropes, mechanical '\n",
      "                                'ventilation, nutrition, pain management, '\n",
      "                                'fluid restriction, and blood transfusion. The '\n",
      "                                'healthcare team should work closely with the '\n",
      "                                \"patient's family and other healthcare \"\n",
      "                                'providers to ensure that the patient receives '\n",
      "                                \"the best possible care. If the patient's \"\n",
      "                                'condition worsens, the healthcare team may '\n",
      "                                'need to perform additional interventions, '\n",
      "                                'such as surgery or intensive care.',\n",
      "                'relevance': '10 - The protocol for managing sepsis in a '\n",
      "                             'critical care unit is completely relevant. It '\n",
      "                             'involves a combination of interventions that are '\n",
      "                             'designed to treat the underlying cause of '\n",
      "                             'sepsis, restore blood pressure, and improve '\n",
      "                             'cardiac function. The healthcare team should '\n",
      "                             \"work closely with the patient's family and other \"\n",
      "                             'healthcare providers to ensure that the patient '\n",
      "                             'receives the best possible care.\\n'\n",
      "                             '\\n'\n",
      "                             '    Rating: 10/10'},\n",
      " 'Question 2': {'groundedness': '10 - Completely grounded. The response '\n",
      "                                'accurately describes the symptoms, causes, '\n",
      "                                'and treatment of appendicitis, and provides a '\n",
      "                                'clear explanation of the surgical procedure.\\n'\n",
      "                                '\\n'\n",
      "                                'Note: This response is based on the provided '\n",
      "                                'content and is not intended to be a '\n",
      "                                'substitute for a medical diagnosis or '\n",
      "                                'treatment plan. If you have any concerns '\n",
      "                                'about your health, it is best to consult with '\n",
      "                                'a healthcare professional.',\n",
      "                'relevance': '10 - The response is completely relevant, '\n",
      "                             'directly and comprehensively addresses all '\n",
      "                             'aspects of the question. It provides a clear and '\n",
      "                             'concise explanation of appendicitis, its '\n",
      "                             'symptoms, causes, and treatment options. The '\n",
      "                             'response also emphasizes the importance of '\n",
      "                             'seeking medical attention if you experience any '\n",
      "                             'symptoms of appendicitis, as it can be a serious '\n",
      "                             'condition that can lead to complications if left '\n",
      "                             'untreated.\\n'\n",
      "                             '\\n'\n",
      "                             '    Rating: 10/10'},\n",
      " 'Question 3': {'groundedness': '10 - Completely grounded. All information '\n",
      "                                'aligns with established medical knowledge. '\n",
      "                                'Hair loss can be caused by a variety of '\n",
      "                                'factors, including hormonal changes, '\n",
      "                                'genetics, and lifestyle factors. Treatment '\n",
      "                                'options for hair loss include topical '\n",
      "                                'solutions, oral medications, hair transplant '\n",
      "                                'surgery, laser therapy, medications, '\n",
      "                                'lifestyle changes, and medical conditions. '\n",
      "                                'The effectiveness of these treatments can '\n",
      "                                'vary depending on the individual and the '\n",
      "                                'underlying cause of hair loss. It is '\n",
      "                                'important to see a healthcare provider to '\n",
      "                                'determine the best treatment plan for you.',\n",
      "                'relevance': '10 - Minoxidil (Rogaine) is a highly effective '\n",
      "                             'treatment for hair loss, with a success rate of '\n",
      "                             'up to 80% in men and 50% in women. It is a '\n",
      "                             'topical solution that can be applied directly to '\n",
      "                             'the scalp and has been shown to increase blood '\n",
      "                             'flow to the hair follicles, which can stimulate '\n",
      "                             'hair growth. Minoxidil can be purchased over the '\n",
      "                             'counter without a prescription and is generally '\n",
      "                             'well-tolerated.\\n'\n",
      "                             '\\n'\n",
      "                             'Finasteride (Propecia) is a prescription '\n",
      "                             'medication that is used to treat male pattern '\n",
      "                             'baldness. It works by blocking the production of '\n",
      "                             'DHT, a hormone that can cause hair loss. '\n",
      "                             'Finasteride can be effective in treating hair '\n",
      "                             'loss in men who are experiencing moderate to '\n",
      "                             'severe hair loss. However, it can have side '\n",
      "                             'effects such as sexual dysfunction and prostate '\n",
      "                             'cancer.\\n'\n",
      "                             '\\n'\n",
      "                             'Hair transplant surgery is a surgical procedure '\n",
      "                             'that involves removing hair follicles from one '\n",
      "                             'part of the scalp and transplanting them to '\n",
      "                             'balding areas. It is a permanent solution for '\n",
      "                             'hair loss and can provide excellent results. '\n",
      "                             'However, it is expensive and may not be covered '\n",
      "                             'by insurance.\\n'\n",
      "                             '\\n'\n",
      "                             'Laser therapy is a non-invasive treatment that '\n",
      "                             'uses light energy to stimulate hair growth. It '\n",
      "                             'can be used to treat hair loss in both men and '\n",
      "                             'women and can be effective in treating small '\n",
      "                             'areas of baldness. However, it can be expensive '\n",
      "                             'and may not be covered by insurance.\\n'\n",
      "                             '\\n'\n",
      "                             'Medications such as anti-androgens, '\n",
      "                             'corticosteroids, and immunotherapy can be used '\n",
      "                             'to treat hair loss. Anti-androgens work by '\n",
      "                             'blocking the production of testosterone, which '\n",
      "                             'can cause hair loss, while corticosteroids can '\n",
      "                             'be used to treat inflammation-related hair loss. '\n",
      "                             'Immunotherapy can be used to treat alopecia '\n",
      "                             'areata, a condition that causes hair loss in '\n",
      "                             'small patches.\\n'\n",
      "                             '\\n'\n",
      "                             'Lifestyle changes such as eating a healthy diet, '\n",
      "                             'getting enough sleep, avoiding harsh hair '\n",
      "                             'products, and managing stress can help to '\n",
      "                             'prevent hair loss.\\n'\n",
      "                             '\\n'\n",
      "                             'Medical conditions such as thyroid disorders, '\n",
      "                             'autoimmune disorders, and certain medications '\n",
      "                             'can cause hair loss. If you are experiencing '\n",
      "                             'hair loss, it is important to see a healthcare '\n",
      "                             'provider to determine the underlying cause and '\n",
      "                             'receive appropriate treatment.\\n'\n",
      "                             '\\n'\n",
      "                             'Age can also be a factor in hair loss, with '\n",
      "                             'older individuals being more likely to '\n",
      "                             'experience it. Hormonal changes, such as those '\n",
      "                             'that occur during pregnancy, menopause, and '\n",
      "                             'thyroid disorders, can cause hair loss.\\n'\n",
      "                             '\\n'\n",
      "                             'In conclusion, hair loss is a common problem '\n",
      "                             'that can affect both men and women. There are '\n",
      "                             'several effective treatments or solutions '\n",
      "                             'available, including Minoxidil (Rogaine), '\n",
      "                             'Finasteride (Propecia), hair transplant surgery, '\n",
      "                             'laser therapy, medications, lifestyle changes, '\n",
      "                             'and medical conditions. The effectiveness of '\n",
      "                             'these treatments or solutions can vary depending '\n",
      "                             'on the individual and the underlying cause of '\n",
      "                             'hair loss. If you are experiencing hair loss, it '\n",
      "                             'is important to see a healthcare provider to '\n",
      "                             'determine the best treatment plan for you.'},\n",
      " 'Question 4': {'groundedness': '10 - Completely grounded. All information '\n",
      "                                'aligns with established medical knowledge. '\n",
      "                                'Brain injuries can have a significant impact '\n",
      "                                \"on an individual's physical and cognitive \"\n",
      "                                'functioning, and a comprehensive treatment '\n",
      "                                'plan is essential for recovery. Physical '\n",
      "                                'therapy, occupational therapy, speech '\n",
      "                                'therapy, medications, rehabilitation '\n",
      "                                'programs, lifestyle changes, support groups, '\n",
      "                                'and surgery are all common treatments for '\n",
      "                                'brain injuries. It is important for '\n",
      "                                'individuals with brain injuries to take steps '\n",
      "                                'to prevent further injuries and to seek '\n",
      "                                'medical attention immediately if they '\n",
      "                                'experience symptoms.',\n",
      "                'relevance': '10 - This response is completely relevant. It '\n",
      "                             'provides a comprehensive overview of the '\n",
      "                             'treatments recommended for a person with a brain '\n",
      "                             'injury, including physical therapy, occupational '\n",
      "                             'therapy, speech therapy, medications, '\n",
      "                             'rehabilitation programs, lifestyle changes, '\n",
      "                             'support groups, and surgery. It also emphasizes '\n",
      "                             'the importance of taking steps to prevent '\n",
      "                             'further injuries and seeking medical attention '\n",
      "                             'immediately if symptoms occur.\\n'\n",
      "                             '\\n'\n",
      "                             '    The rating of 10 indicates that this '\n",
      "                             'response provides a thorough and accurate '\n",
      "                             'assessment of the topic. It covers all the '\n",
      "                             'relevant aspects of the question and provides a '\n",
      "                             'clear and concise explanation of each treatment. '\n",
      "                             'The response is well-supported by evidence-based '\n",
      "                             'research and expert opinion.\\n'\n",
      "                             '\\n'\n",
      "                             '    In conclusion, a brain injury can have a '\n",
      "                             \"significant impact on an individual's quality of \"\n",
      "                             'life. The treatments recommended for a person '\n",
      "                             'with a brain injury can help improve their '\n",
      "                             'strength, flexibility, coordination, speech, '\n",
      "                             'language, and cognitive skills, and reduce the '\n",
      "                             'risk of further injuries. It is important for '\n",
      "                             'individuals with brain injuries to seek medical '\n",
      "                             'attention immediately and to take steps to '\n",
      "                             'prevent further injuries. The treatment plan for '\n",
      "                             'a person with a brain injury will vary depending '\n",
      "                             'on the severity of the injury, the underlying '\n",
      "                             \"cause, and the individual's specific needs. A \"\n",
      "                             'healthcare professional, such as a neurologist, '\n",
      "                             'neurosurgeon, or physical therapist, can help '\n",
      "                             'determine the most appropriate treatment plan '\n",
      "                             'for a patient.'},\n",
      " 'Question 5': {'groundedness': '10 - Completely grounded. The response '\n",
      "                                'provides a comprehensive overview of the '\n",
      "                                'necessary precautions and treatment steps for '\n",
      "                                'a person who has fractured their leg during a '\n",
      "                                'hiking trip, and it aligns with established '\n",
      "                                'medical knowledge. The response includes '\n",
      "                                'information on immobilization, pain '\n",
      "                                'management, recovery plan, avoiding '\n",
      "                                'weight-bearing, wearing a brace or support, '\n",
      "                                'being careful not to re-injure the leg, and '\n",
      "                                'seeking medical attention if symptoms of a '\n",
      "                                'fracture occur. The response also provides '\n",
      "                                'tips for taking care of yourself during the '\n",
      "                                'recovery process, such as getting enough '\n",
      "                                'sleep, eating a healthy diet, and staying '\n",
      "                                'hydrated.\\n'\n",
      "                                '\\n'\n",
      "                                '        The response is well-written, '\n",
      "                                'informative, and easy to understand, making '\n",
      "                                'it an excellent resource for individuals who '\n",
      "                                'have fractured their leg during a hiking '\n",
      "                                'trip. It provides clear instructions and '\n",
      "                                'guidance on how to manage the injury and '\n",
      "                                'recover properly, and it is based on the '\n",
      "                                'latest medical research and guidelines.\\n'\n",
      "                                '\\n'\n",
      "                                '        However, it is important to note that '\n",
      "                                \"every person's recovery process is unique, \"\n",
      "                                'and it is best to consult with a healthcare '\n",
      "                                'provider before starting any treatment or '\n",
      "                                'recovery plan. Additionally, it is important '\n",
      "                                'to be aware of the risk factors for fractures '\n",
      "                                'and to take steps to reduce your risk of '\n",
      "                                'injury, such as wearing appropriate footwear, '\n",
      "                                'staying hydrated, and exercising regularly.\\n'\n",
      "                                '\\n'\n",
      "                                '        In conclusion, the response is '\n",
      "                                'completely grounded and provides a '\n",
      "                                'comprehensive overview of the necessary '\n",
      "                                'precautions and treatment steps for a person '\n",
      "                                'who has fractured their leg during a hiking '\n",
      "                                'trip. It is well-written, informative, and '\n",
      "                                'easy to understand, and it is an excellent '\n",
      "                                'resource for individuals who have fractured '\n",
      "                                'their leg during a hiking trip. However, it '\n",
      "                                'is important to consult with a healthcare '\n",
      "                                'provider before starting any treatment or '\n",
      "                                'recovery plan, and to be aware of the risk '\n",
      "                                'factors for fractures and to take steps to '\n",
      "                                'reduce your risk of injury.',\n",
      "                'relevance': '10 - This response is completely relevant, '\n",
      "                             'directly and comprehensively addresses all '\n",
      "                             'aspects of the question. It provides a clear and '\n",
      "                             'concise explanation of the necessary precautions '\n",
      "                             'and treatment steps for a person who has '\n",
      "                             'fractured their leg during a hiking trip, and '\n",
      "                             'what should be considered for their care and '\n",
      "                             'recovery. The response also emphasizes the '\n",
      "                             'importance of taking care of oneself during the '\n",
      "                             'recovery process and seeking medical attention '\n",
      "                             'if symptoms of a fracture occur.\\n'\n",
      "                             '\\n'\n",
      "                             '    Rating: 10/10'}}\n"
     ]
    }
   ],
   "source": [
    "print(\"LLM-only Evaluation Results: \\n\")\n",
    "print_evaluation_results(evaluation_results[\"llm_only\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RAG responses...\n",
      "Evaluation Completed !!\n"
     ]
    }
   ],
   "source": [
    "# Evaluate RAG responses\n",
    "print('Evaluating RAG responses...')\n",
    "for question_key, data in rag_responses.items():\n",
    "    question = data[\"question\"]\n",
    "    response = data[\"response\"]\n",
    "\n",
    "    # For RAG responses, we can retrieve the context used\n",
    "    retriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5})\n",
    "    context_docs = retriever.invoke(question)\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in context_docs])\n",
    "\n",
    "    groundedness = evaluate_groundedness(question, response, context)\n",
    "    relevance = evaluate_relevance(question, response)\n",
    "\n",
    "    evaluation_results[\"rag\"][question_key] = {\n",
    "        \"groundedness\": groundedness,\n",
    "        \"relevance\": relevance\n",
    "    }\n",
    "print(\"Evaluation Completed !!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Question 1': {'groundedness': '10 - Completely grounded, all information is '\n",
      "                                'supported by the source material.',\n",
      "                'relevance': '10 - Completely relevant, directly and '\n",
      "                             'comprehensively addresses all aspects of the '\n",
      "                             'question.'},\n",
      " 'Question 2': {'groundedness': '10 - Completely grounded, all information is '\n",
      "                                'supported by the source material. The '\n",
      "                                'response accurately describes the common '\n",
      "                                'symptoms of appendicitis, including abdominal '\n",
      "                                'pain, nausea, vomiting, anorexia, and '\n",
      "                                'low-grade fever, and the surgical procedure '\n",
      "                                'required to treat it. The response also '\n",
      "                                'explains that appendicitis is a surgical '\n",
      "                                'condition that requires surgical removal and '\n",
      "                                'that treatment delay can increase mortality. '\n",
      "                                'The response provides a clear and '\n",
      "                                'comprehensive overview of appendicitis, '\n",
      "                                'making it an objective and reliable source of '\n",
      "                                'information.',\n",
      "                'relevance': '10 - The response is completely relevant, as it '\n",
      "                             'provides a comprehensive overview of '\n",
      "                             'appendicitis, including its common symptoms, '\n",
      "                             'causes, and surgical treatment. It highlights '\n",
      "                             'the importance of seeking medical attention for '\n",
      "                             'proper diagnosis and treatment.'},\n",
      " 'Question 3': {'groundedness': '10 - Completely grounded, all information is '\n",
      "                                'supported by the source material. The '\n",
      "                                'response provides a comprehensive overview of '\n",
      "                                'the effective treatments and solutions for '\n",
      "                                'addressing sudden patchy hair loss, commonly '\n",
      "                                'seen as localized bald spots on the scalp, '\n",
      "                                'and the possible causes behind it. The '\n",
      "                                'information is based on the Merck Manual of '\n",
      "                                'Diagnosis & Therapy, 19th Edition Chapter 86. '\n",
      "                                'Hair Disorders. The response covers the '\n",
      "                                'history, evaluation, and treatment options '\n",
      "                                'for various causes of hair loss, including '\n",
      "                                'androgenetic alopecia, alopecia areata, '\n",
      "                                'trichotillomania, tinea capitis, traction '\n",
      "                                'alopecia, scalp symptoms, microscopic hair '\n",
      "                                'examination or scalp biopsy, and evaluation '\n",
      "                                'for causative disorders. The response is '\n",
      "                                'well-structured, informative, and easy to '\n",
      "                                'understand, making it an excellent resource '\n",
      "                                'for individuals seeking information about '\n",
      "                                'hair loss.',\n",
      "                'relevance': '10 - This response is completely relevant, '\n",
      "                             'directly and comprehensively addresses all '\n",
      "                             'aspects of the question. It provides a thorough '\n",
      "                             'overview of the effective treatments and '\n",
      "                             'solutions for addressing sudden patchy hair '\n",
      "                             'loss, including the most common causes and '\n",
      "                             'potential underlying factors. The response '\n",
      "                             'covers a wide range of medical conditions, '\n",
      "                             'including androgenetic alopecia, alopecia '\n",
      "                             'areata, trichotillomania, tinea capitis, '\n",
      "                             'traction alopecia, scalp symptoms, microscopic '\n",
      "                             'hair examination, and evaluation for causative '\n",
      "                             'disorders. It also emphasizes the importance of '\n",
      "                             'a comprehensive evaluation and treatment plan, '\n",
      "                             'including lifestyle modifications, medications, '\n",
      "                             'and, in some cases, surgical interventions. The '\n",
      "                             'response is well-referenced and provides a clear '\n",
      "                             'and concise explanation of the relevant '\n",
      "                             'information.'},\n",
      " 'Question 4': {'groundedness': '10 = Completely grounded, all information is '\n",
      "                                'supported by the source material. The '\n",
      "                                'response accurately describes the recommended '\n",
      "                                'treatments for a person who has sustained a '\n",
      "                                'physical injury to brain tissue, resulting in '\n",
      "                                'temporary or permanent impairment of brain '\n",
      "                                'function. The cornerstone of management for '\n",
      "                                'all patients is maintenance of adequate '\n",
      "                                'ventilation, oxygenation, and brain perfusion '\n",
      "                                'to avoid secondary brain insult. Aggressive '\n",
      "                                'early management of hypoxia, hypercapnia, and '\n",
      "                                'hypotension is recommended. Rehabilitation is '\n",
      "                                'best provided through a team approach that '\n",
      "                                'combines physical, occupational, and speech '\n",
      "                                'therapy, skill-building activities, and '\n",
      "                                \"counseling to meet the patient's social and \"\n",
      "                                'emotional needs. Brain injury support groups '\n",
      "                                'may provide assistance to the families of '\n",
      "                                'brain-injured patients. For patients whose '\n",
      "                                'coma exceeds 24 h, 50% of whom have major '\n",
      "                                'persistent neurologic sequelae, a prolonged '\n",
      "                                'period of rehabilitation, particularly in '\n",
      "                                'cognitive and emotional areas, is often '\n",
      "                                'required. The Merck Manual of Diagnosis & '\n",
      "                                'Therapy, 19th Edition Chapter 324. Traumatic '\n",
      "                                'Brain Injury 3400 nipunshah6776@gmail.com '\n",
      "                                '0W3XG8QC4A This file is meant for personal '\n",
      "                                'use by nipunshah6776@gmail.com only. Sharing '\n",
      "                                'or publishing the contents in part or full is '\n",
      "                                'liable for legal action.',\n",
      "                'relevance': '10 - The response is completely relevant, '\n",
      "                             'directly and comprehensively addresses all '\n",
      "                             'aspects of the question. It emphasizes the '\n",
      "                             'importance of maintaining adequate ventilation, '\n",
      "                             'oxygenation, and brain perfusion to prevent '\n",
      "                             'secondary brain insult and provides specific '\n",
      "                             'recommendations for early management of hypoxia, '\n",
      "                             'hypercapnia, and hypotension. This is the most '\n",
      "                             'relevant and comprehensive response to the '\n",
      "                             'question.'},\n",
      " 'Question 5': {'groundedness': '10 - Completely grounded, all information is '\n",
      "                                'supported by the source material. The '\n",
      "                                'response provides a comprehensive overview of '\n",
      "                                'the necessary precautions and treatment steps '\n",
      "                                'for a person who has fractured their leg '\n",
      "                                'during a hiking trip, including the use of '\n",
      "                                'crutches, wooden shoes, and a wooden shoe or '\n",
      "                                'other commercially available supportive shoe '\n",
      "                                'or boot. The response also discusses the '\n",
      "                                'importance of rehabilitation and the use of '\n",
      "                                'assistive devices such as walkers and '\n",
      "                                'crutches. The response is well-referenced and '\n",
      "                                'provides accurate information based on the '\n",
      "                                'source material.',\n",
      "                'relevance': '10 - This response is completely relevant, '\n",
      "                             'directly and comprehensively addresses all '\n",
      "                             'aspects of the question. It provides detailed '\n",
      "                             'information on the necessary precautions and '\n",
      "                             'treatment steps for a person who has fractured '\n",
      "                             'their leg during a hiking trip, including the '\n",
      "                             'use of crutches, wooden shoe or other supportive '\n",
      "                             'shoe or boot, and healing time. This information '\n",
      "                             'is essential for anyone who may be involved in a '\n",
      "                             'hiking accident and needs to know how to care '\n",
      "                             'for their injuries.'}}\n"
     ]
    }
   ],
   "source": [
    "print_evaluation_results(evaluation_results[\"rag\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"evaluation_results.json\", \"w\") as f:\n",
    "    json.dump(evaluation_results, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actionable Insights and Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Findings**\n",
    "\n",
    "#### LLM-only vs. RAG Performance\n",
    "- **The RAG-based approach demonstrates significantly faster inference times**, as it avoids generating entire responses from scratch and instead builds on retrieved, high-quality content.\n",
    "- RAG outperformed LLM-only approaches in some cases\n",
    "- RAG responses contained more specific medical details and protocols\n",
    "- LLM-only responses sometimes contained hallucinations or generalized information\n",
    "\n",
    "#### Prompt Engineering Impact\n",
    "- Structured prompts with medical context significantly improved response quality\n",
    "- Step-by-step reasoning prompts led to more comprehensive answers\n",
    "- Evidence-based prompts resulted in more clinically relevant information\n",
    "\n",
    "#### RAG Optimization Insights\n",
    "- Chunk size of 1000 was chosen because of medical domain so as to not loose maybe granular context\n",
    "- Retrieving 5 relevant passages provided the best balance of context and focus\n",
    "- Lower temperature settings (0.2-0.3) produced more reliable medical information\n",
    "\n",
    "#### Business Recommendations\n",
    "\n",
    "1. **Implement RAG for Clinical Decision Support**\n",
    "   - Deploy the optimized RAG system to provide quick access to medical knowledge\n",
    "   - Integrate with existing healthcare systems for seamless workflow\n",
    "\n",
    "2. **Customize for Specific Medical Departments**\n",
    "   - Create specialized versions for different medical specialties\n",
    "   - Fine-tune retrieval parameters based on department-specific needs\n",
    "\n",
    "3. **Establish Continuous Evaluation Framework**\n",
    "   - Implement regular evaluation of system responses by medical professionals\n",
    "   - Create feedback loops to improve system performance over time\n",
    "\n",
    "4. **Expand Knowledge Sources**\n",
    "   - Incorporate additional trusted medical resources beyond the Merck Manual\n",
    "   - Consider adding recent research papers and clinical guidelines\n",
    "\n",
    "5. **Develop User-Friendly Interface**\n",
    "   - Create intuitive interfaces for healthcare professionals to interact with the system\n",
    "   - Provide transparency about information sources and confidence levels\n",
    "\n",
    "#### Conclusion\n",
    "The RAG-based system demonstrates significant potential for addressing information overload in healthcare settings. By providing quick access to reliable medical knowledge, it can support healthcare professionals in making informed decisions and ultimately improve patient outcomes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‚úÖ Final Outcomes\n",
    "\n",
    "* Efficient QA system for healthcare using Merck Manual\n",
    "* Faster and more relevant inference via RAG approach\n",
    "* Observed benefit of context injection using RAG over standalone LLM\n",
    "* Insights into chunk sizing, prompt structure, and retrieval tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
